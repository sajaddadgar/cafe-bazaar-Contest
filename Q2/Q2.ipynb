{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tRCpQCPFqi_-"
   },
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Z3hkjbIFzmTP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hazm in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (0.7.0)\n",
      "Requirement already satisfied: nltk==3.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from hazm) (3.3)\n",
      "Requirement already satisfied: six in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from nltk==3.3->hazm) (1.15.0)\n",
      "Requirement already satisfied: pip in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (20.3)\n",
      "Requirement already satisfied: install in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (1.3.4)\n",
      "Requirement already satisfied: stopwords-guilannlp in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (13.2019.3.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install hazm\n",
    "!pip install pip install stopwords-guilannlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "from stopwords_guilannlp import stopwords_output\n",
    "from hazm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "tJ8_z8yxzmTL"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dense, Activation, LSTM, Dropout, Embedding,\\\n",
    "  Bidirectional, GlobalMaxPool1D, Conv1D, Flatten, GlobalMaxPooling1D\n",
    "\n",
    "from keras.backend import clear_session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F8wTb0mCxg9Y"
   },
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "Rtsn3VV6zmTP",
    "outputId": "2e033a3d-a894-4676-f38e-cdc015a8a429"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>description_fa</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;p&gt;بازی مین روب یک برنامه فکری است که باید مین...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;دراین بازی تعدادی عکس برای شما نشان داده می...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;br&gt;تلاش نافرجام برای درک «بوفالو»&lt;br&gt;مرگ پایا...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>&lt;p&gt;فیلم نما ، برنامه ای برای دانلود و پخش آنلا...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>&lt;p&gt;* این برنامه حاوی بیش از 500 عکس و ژست برای...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   app_id                                     description_fa  label\n",
       "0       0  <p>بازی مین روب یک برنامه فکری است که باید مین...      1\n",
       "1       1  <p>دراین بازی تعدادی عکس برای شما نشان داده می...      1\n",
       "2       2  <br>تلاش نافرجام برای درک «بوفالو»<br>مرگ پایا...      7\n",
       "3       3  <p>فیلم نما ، برنامه ای برای دانلود و پخش آنلا...      7\n",
       "4       4  <p>* این برنامه حاوی بیش از 500 عکس و ژست برای...      7"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('train_set.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GBoTcKC70OnG"
   },
   "source": [
    "### Data distribution visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "6harI_njxvLm",
    "outputId": "d253af82-0e30-4a55-c5f3-2f627eaafefa"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df_train['label'], bins=30, color='#607c8e')\n",
    "plt.xticks(np.arange(0, 10, step=1))\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Label')\n",
    "plt.title('Distribution of the labels in the training set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kDKl3l9s0G7I"
   },
   "source": [
    "### Dependent and independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iqce8-k4zmTQ",
    "outputId": "879aa5b2-5fc3-4631-f8a9-ee2cda27c174"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: <p>بازی مین روب یک برنامه فکری است که باید مین های موجود در صفحه بازی را کشف کنید .قابلیت های این برنامه عبارتند از : <br> </br></p> <p>- دارای سطوح مختلف دشواری از آسان به سخت <br> </br></p> <p>- امکان تعریف بازی سفارشی <br> </br></p> <p>- نمایش آمار بازی ها و عملکرد شما <br> </br></p> <p>- ذخیره تمام بازی های ناتمام، در این صورت میتوانید در آینده به قسمت بازی های ذخیره شده مراجعه کنید و بازی را ادامه دهید. <br> </br></p> <p>از سایر برنامه و بازی های متنوع ما نیز دیدن کنید. <br> </br></p> <p>سپاسگزارم. <br> </br></p>\n",
      "y: 1\n"
     ]
    }
   ],
   "source": [
    "X = df_train.iloc[:, 1].values\n",
    "y = df_train.iloc[:, 2].values\n",
    "\n",
    "print(\"X: {}\".format(X[0]))\n",
    "print(\"y: {}\".format(y[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CREL7l5NzmTQ"
   },
   "source": [
    "# Preprocessing the textual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "-LFs0vCL6ooJ"
   },
   "outputs": [],
   "source": [
    "# Stopwords\n",
    "stop_set = stopwords_output(\"Persian\", \"set\")\n",
    "customized_stop_words = ['&nbsp;','nbsp']\n",
    "def text_preprocess(text):\n",
    "  # Remove HTML tags \n",
    "  text = re.sub(r'<(.*?)>', '', str(text))\n",
    "\n",
    "  wierd_pattern = re.compile(\"[\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u200c\"\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "\n",
    "  text = wierd_pattern.sub(r'', text)\n",
    "\n",
    "  # Tokenize the text\n",
    "  tokenized = word_tokenize(text)\n",
    "  tokens = []\n",
    "  for word in tokenized:\n",
    "    for sw in customized_stop_words:\n",
    "      word = word.replace(sw, '')\n",
    "      # Remove 1 letter words and stopwords\n",
    "    if (word.isalpha() and not (len(word)<=1)) and not (word in stop_set):\n",
    "      tokens.append(word)\n",
    "  # Return as a string\n",
    "  tokens = ' '.join(tokens)\n",
    "  return tokens\n",
    "\n",
    "def preprocess(data):\n",
    "  data_list = []\n",
    "  for text in data:\n",
    "    data_list.append(text_preprocess(text))\n",
    "  return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DNsn5l4QsvyP",
    "outputId": "c76d061a-d7b3-4c31-e306-a3c52231831a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: <p>بازی مین روب یک برنامه فکری است که باید مین های موجود در صفحه بازی را کشف کنید .قابلیت های این برنامه عبارتند از : <br> </br></p> <p>- دارای سطوح مختلف دشواری از آسان به سخت <br> </br></p> <p>- امکان تعریف بازی سفارشی <br> </br></p> <p>- نمایش آمار بازی ها و عملکرد شما <br> </br></p> <p>- ذخیره تمام بازی های ناتمام، در این صورت میتوانید در آینده به قسمت بازی های ذخیره شده مراجعه کنید و بازی را ادامه دهید. <br> </br></p> <p>از سایر برنامه و بازی های متنوع ما نیز دیدن کنید. <br> </br></p> <p>سپاسگزارم. <br> </br></p>\n",
      "After: بازی مین برنامه فکری مین موجود صفحه بازی کشف قابلیت برنامه دارای سطوح دشواری آسان امکان تعریف بازی سفارشی نمایش آمار بازی عملکرد ذخیره بازی ناتمام میتوانید آینده قسمت بازی ذخیره مراجعه بازی ادامه برنامه بازی متنوع دیدن سپاسگزارم\n"
     ]
    }
   ],
   "source": [
    "X_process = preprocess(X)\n",
    "\n",
    "print('Before: {}'.format(X[0]))\n",
    "print('After: {}'.format(X_process[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "WxzS4vwQzmTU"
   },
   "outputs": [],
   "source": [
    "def save_ML_Result(model):\n",
    "    df_test = pd.read_csv('test_set.csv')\n",
    "    test_X = df_test.iloc[:, 1].values\n",
    "    test_X_preproc = preprocess(test_X)\n",
    "    preprocess_X_test_cv = tf_idf.transform(test_X_preproc)\n",
    "    test_prediction = model.predict(preprocess_X_test_cv)\n",
    "    output = [int(i) for i in test_prediction]\n",
    "    df_test['label'] = output\n",
    "    df_test.drop(['description_fa'], axis=1, inplace=True)\n",
    "    df_test.to_csv('prediction.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCkbULL9e7vj"
   },
   "source": [
    "# Model construction\n",
    "In this question, we implemented machine learning models divided into traditional machine learning, ensemble-based model, and deep learning models. For each model, we tuned the hyperparameter for achieving the best results. Also, we split 10% of the training set for the validation set. Since training models with more data gives better result, we used all of the training set in models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1kI1hEmzmTU"
   },
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "-ja9JoaQzmTV"
   },
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer()\n",
    "X_train_cv = tf_idf.fit_transform(X_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DAnnxqYmgsdo"
   },
   "source": [
    "## Traditional machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jzgmHPJfzmTV"
   },
   "source": [
    "### 1. Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0nXfYp5qzmTW"
   },
   "source": [
    "#### Hyperparameter tuning using the Grid search method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g8Cl-TJ8zmTW",
    "outputId": "5b53e74a-2786-4df9-b3fb-971f941bb48c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 70.48 %\n",
      "Best Parameters: {'alpha': 0.1, 'fit_prior': False}\n"
     ]
    }
   ],
   "source": [
    "naive_bayes = MultinomialNB()\n",
    "parameters = [{'alpha': [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1], 'fit_prior': [True, False]}]\n",
    "\n",
    "grid_search = GridSearchCV(estimator = naive_bayes,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "\n",
    "grid_search = grid_search.fit(X_train_cv, y)\n",
    "\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "\n",
    "print(\"Best Accuracy: {:.2f} %\".format(best_accuracy*100))\n",
    "print(\"Best Parameters:\", best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "SB8FzKHYzmTW"
   },
   "outputs": [],
   "source": [
    "# Initializing the model\n",
    "naive_bayes = MultinomialNB(alpha=0.1, fit_prior=False)\n",
    "# Fitting the data into the model\n",
    "naive_bayes.fit(X_train_cv, y)\n",
    "# prediction = naive_bayes.predict(X_test_cv)\n",
    "save_ML_Result(naive_bayes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dToxPSYXzmTX"
   },
   "source": [
    "### 2. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fm6fu3-nzmTX"
   },
   "source": [
    "#### Hyperparameter tuning using the Grid search method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T6H_kYf9zmTX",
    "outputId": "be711f3d-816e-46f4-a70b-94a1bf6cccd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 73.07 %\n",
      "Best Parameters: {'C': 1, 'penalty': 'l2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "logistic_regression = LogisticRegression(max_iter=100)\n",
    "parameters = [{'C': [0, 0.5, 1, 5, 10, 50, 100, 200, 500], 'penalty': ['l1', 'l2']}]\n",
    "\n",
    "grid_search = GridSearchCV(estimator = logistic_regression,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "\n",
    "grid_search = grid_search.fit(X_train_cv, y)\n",
    "\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "\n",
    "print(\"Best Accuracy: {:.2f} %\".format(best_accuracy*100))\n",
    "print(\"Best Parameters:\", best_parameters)\n",
    "\n",
    "grid_search = GridSearchCV(estimator = logistic_regression,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "\n",
    "grid_search = grid_search.fit(X_train_cv, y)\n",
    "\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "\n",
    "print(\"Best Accuracy: {:.2f} %\".format(best_accuracy*100))\n",
    "print(\"Best Parameters:\", best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "_xaYlCfUzmTX"
   },
   "outputs": [],
   "source": [
    "# Initializing the model\n",
    "logistic_regression = LogisticRegression(C=1, penalty='l2', max_iter=1000)\n",
    "# Fitting the data into the model\n",
    "logistic_regression.fit(X_train_cv, y)\n",
    "# prediction = logistic_regression.predict(X_test_cv)\n",
    "save_ML_Result(logistic_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8wx2ocudzmTY"
   },
   "source": [
    "### 3. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "Oqi8MOTkzmTY"
   },
   "outputs": [],
   "source": [
    "# Initializing the model\n",
    "svm = SVC(kernel = 'rbf', C=100)\n",
    "# Fitting the data into the model\n",
    "svm.fit(X_train_cv, y)\n",
    "# Prediction\n",
    "# prediction = svm.predict(X_test_cv)\n",
    "save_ML_Result(svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jYOe6wW3zmTY"
   },
   "source": [
    "### 4. Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zemjIUNJzmTY"
   },
   "source": [
    "#### Hyperparameter tuning using the Grid search method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e0UzhKL2zmTZ"
   },
   "outputs": [],
   "source": [
    "decision_Tree = DecisionTreeClassifier()\n",
    "parameters = [{'criterion':['gini','entropy'], 'max_depth':[None, 1, 5, 10, 20, 50, 90, 100, 150], 'max_features':[None, 'sqrt', 'auto', 'log2'], 'min_samples_split':[1, 2, 5, 10, 20, 40], 'min_samples_leaf':[1, 2, 5, 10, 20,]}]\n",
    "\n",
    "grid_search = GridSearchCV(estimator = decision_Tree,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "\n",
    "grid_search = grid_search.fit(X_train_cv, y)\n",
    "\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "\n",
    "print(\"Best Accuracy: {:.2f} %\".format(best_accuracy*100))\n",
    "print(\"Best Parameters:\", best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t-wIqDe6zmTZ"
   },
   "outputs": [],
   "source": [
    "# Initializing the model\n",
    "decision_Tree = DecisionTreeClassifier(criterion = 'entropy', max_depth=100)\n",
    "# Fitting the data into the model\n",
    "decision_Tree.fit(X_train_cv, y)\n",
    "# prediction = decision_Tree.predict(X_test_cv)\n",
    "save_ML_Result(decision_Tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2yJioEw2hT-P"
   },
   "source": [
    "## Ensemble-based models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1eym93IzmTZ"
   },
   "source": [
    "### 5. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cx0glPf4zmTa"
   },
   "outputs": [],
   "source": [
    "# Initializing the model\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "# Fitting the data into the model\n",
    "random_forest.fit(X_train_cv, y)\n",
    "# Prediction\n",
    "# prediction = random_forest.predict(X_test_cv)\n",
    "save_ML_Result(random_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewNOTyIBzmTa"
   },
   "source": [
    "### 6. Sacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z8tFLpTyzmTb"
   },
   "outputs": [],
   "source": [
    "estimators = [('naive bayes', naive_bayes),\n",
    "              ('svm', svm),\n",
    "              ('decision tree', decision_Tree),\n",
    "              ('logistic regression', logistic_regression)]\n",
    "Stacking = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "Stacking.fit(X_train_cv, y)\n",
    "save_ML_Result(Stacking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GcplCuZWzmTb"
   },
   "source": [
    "## Deep learning models\n",
    "For Deep learning model, we encode preprocessed textual data using one-hot encoding and pad them to the maximum length.<br>\n",
    "for consuming time and saving space we did not o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EqF3R8AEzmTc"
   },
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "_ho003DfzmTc"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train_set.csv')\n",
    "df_test = pd.read_csv('test_set.csv')\n",
    "\n",
    "X = df_train.iloc[:, 1].values\n",
    "y = df_train.iloc[:, 2].values\n",
    "\n",
    "X_preproc = preprocess(X)\n",
    "test_X = df_test.iloc[:, 1].values\n",
    "test_X_preproc = preprocess(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-FGCr8RczmTg"
   },
   "outputs": [],
   "source": [
    "def get_vocab_size(X_train_preproc, X_test_preproc):\n",
    "    text_data = []\n",
    "    vocab = []\n",
    "\n",
    "    for i in X_train_preproc:\n",
    "        text_data.append(i)\n",
    "    for i in X_test_preproc:\n",
    "        text_data.append(i)\n",
    "#     for i in test_x:\n",
    "#         text_data.append(i)\n",
    "\n",
    "    for text in text_data:\n",
    "        text_list = text.split(' ')\n",
    "        for word in text_list:\n",
    "            vocab.append(word)\n",
    "    vocab_size = len(set(vocab))\n",
    "\n",
    "    num_token = [len(tokens.split(' ')) for tokens in X_train_preproc + test_X_preproc]\n",
    "    num_token = np.array(num_token)\n",
    "    max_token = np.mean(num_token) + 2 * np.std(num_token)\n",
    "    max_token = int(max_token)\n",
    "\n",
    "    return vocab_size, max_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D-UyHDFJzmTg",
    "outputId": "ee21e25b-31ad-476e-baad-0b8fccaaf1b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205239, 195)"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size, max_token = get_vocab_size(X_preproc, test_X_preproc)\n",
    "vocab_size, max_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xgKGj6cmzmTh"
   },
   "outputs": [],
   "source": [
    "# for consuming time and saving space, we didn't use one-hot y.\n",
    "# Therefore we use sparse_categorical_crossentropy as the loss function\n",
    "X_onehot_train = [one_hot(words,vocab_size) for words in X_preproc] \n",
    "X_onehot_test = [one_hot(words,vocab_size) for words in test_X_preproc] \n",
    "\n",
    "train_embedded_docs=pad_sequences(X_onehot_train,padding='pre',maxlen=max_token)\n",
    "test_embedded_docs=pad_sequences(X_onehot_test,padding='pre',maxlen=max_token)\n",
    "\n",
    "X_train_final=np.array(train_embedded_docs)\n",
    "X_test_final=np.array(test_embedded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JcZS4v5fju8C"
   },
   "source": [
    "### 7. Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "klNC_AKHfvJK"
   },
   "outputs": [],
   "source": [
    "clear_session()\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 200, input_length=max_token))\n",
    "model.add(Bidirectional(LSTM(100, return_sequences=True, name='lstm_layer')))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(200, activation=\"relu\"))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "my_callbacks = [\n",
    "    EarlyStopping(patience=5, monitor='val_accuracy', mode='min'),\n",
    "    ModelCheckpoint(\"./saved_models/checkpoints/best_model\", monitor='val_accuracy', verbose=1, save_best_only=True),\n",
    "]\n",
    "\n",
    "model.fit(X_train_final, y, validation_split=0.1, epochs=10, batch_size=64, callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DcONtW5DzmTi"
   },
   "source": [
    "### 8. LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NNKTlo3izmTi",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clear_session()\n",
    "model=Sequential()\n",
    "model.add(Embedding(vocab_size , 200, input_length=max_token))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "my_callbacks = [\n",
    "    EarlyStopping(patience=5, monitor='val_accuracy', mode='min'),\n",
    "    ModelCheckpoint(\"./saved_models/checkpoints/best_model\", monitor='val_accuracy', verbose=1, save_best_only=True),\n",
    "]\n",
    "\n",
    "model.fit(X_train_final, y, validation_split=0.1, epochs=10, batch_size=64, callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9DYMbQu7zmTi"
   },
   "source": [
    "### 9. CNN\n",
    "Although the Convolutional neural network mainly used in text classification, we can use the CNN for text classification as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tsU5bt3AzmTj"
   },
   "outputs": [],
   "source": [
    "clear_session()\n",
    "model=Sequential()\n",
    "model.add(Embedding(vocab_size , 200, input_length=max_token))\n",
    "model.add(Conv1D(100, 5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "my_callbacks = [\n",
    "    EarlyStopping(patience=5, monitor='val_accuracy', mode='min'),\n",
    "    ModelCheckpoint(\"./saved_models/checkpoints/best_model\", monitor='val_accuracy', verbose=1, save_best_only=True),\n",
    "]\n",
    "\n",
    "model.fit(X_train_final, y, validation_split=0.1, epochs=10, batch_size=64, callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8gTIhQbCzmTj"
   },
   "source": [
    "### 10. CNN + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kZh-62y9zmTj"
   },
   "outputs": [],
   "source": [
    "clear_session()\n",
    "model=Sequential()\n",
    "model.add(Embedding(vocab_size , 200, input_length=max_token))\n",
    "model.add(Conv1D(100, 5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "my_callbacks = [\n",
    "    EarlyStopping(patience=5, monitor='val_accuracy', mode='min'),\n",
    "    ModelCheckpoint(\"./saved_models/checkpoints/best_model\", monitor='val_accuracy', verbose=1, save_best_only=True),\n",
    "]\n",
    "\n",
    "model.fit(X_train_final, y, validation_split=0.1, epochs=10, batch_size=64, callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6A0yZ6_-aHjl"
   },
   "source": [
    "### Deep learning models output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t3Sde54kzmTn"
   },
   "outputs": [],
   "source": [
    "best_model = tf.keras.models.load_model(\"./saved_models/checkpoints/best_model\")\n",
    "prediction = best_model.predict_classes(X_test_final)\n",
    "output = [int(i) for i in prediction]\n",
    "df_test = pd.read_csv('test_set.csv')\n",
    "df_test['label'] = output\n",
    "df_test.drop(['description_fa'], axis=1, inplace=True)\n",
    "df_test.to_csv('prediction.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "Based on the result of the above models, the best result was achieved by the Stacking (stacked generalization) with the accuracy of 75.01%. The result of each models on the quera is as follows:\n",
    "\n",
    "| Model | Quera Score |\n",
    "| ------ | ------ |\n",
    "| Naive Bayes | 713 |\n",
    "| Logistic Regression | 736 |\n",
    "| SVM | 749 |\n",
    "| Decision Tree | 595 |\n",
    "| Random Forest | 727 |\n",
    "| **Stacking** | **750** |\n",
    "| Bi-LSTM | 746 |\n",
    "| LSTM | 744 |\n",
    "| CNN | 731 |\n",
    "| CNN + LSTM | 727 |"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Q2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
